**线程束（Warp）详解**

线程束（Warp）是 NVIDIA GPU 最基本的执行单位，由 32 个连续线程 组成，是 SM（流式多处理器）调度和管理的核心单元。理解 Warp 对 CUDA 性能优化至关重要！

---

**1. Warp 的本质**
| 特性 | 说明 |
|------|------|
| 组成 | 1 Warp = 32 个线程（固定大小） |
| 调度 | SM 以 Warp 为单位调度线程（而非单个线程） |
| 执行方式 | SIMT（单指令多线程）：所有线程执行相同指令，但处理不同数据 |
| 分支效率 | 若 Warp 内线程执行不同分支（如 `if-else`），会串行执行（Warp Divergence） |

---

**2. Warp 的工作原理**
**(1) Warp 的生成**
• 当 CUDA 核函数启动时，线程被分组为 Warp。

• 例如：若 Block 有 256 个线程 → 会生成 `256/32 = 8` 个 Warp。


**(2) Warp 调度**
• 每个 SM 有多个 Warp Scheduler（如 Ampere 架构有 4 个）。

• 每个周期，Scheduler 选择一个就绪的 Warp 发射指令。

• 隐藏延迟：当某个 Warp 等待数据时，SM 会切换到其他 Warp 执行（零开销切换）。


**(3) Warp Divergence（线程束分化）**
```c
__global__ void kernel(int *data) {
    if (threadIdx.x % 2 == 0) {
        data[threadIdx.x] *= 2;  // 分支A
    } else {
        data[threadIdx.x] += 1;  // 分支B
    }
}
```
• 问题：Warp 中的线程会串行执行分支 A 和 B（即使只有 1 个线程走不同分支）。

• 优化：尽量让 Warp 内所有线程走相同分支。


---

**3. Warp 相关的关键概念**
**(1) Occupancy（占用率）**
• 定义：SM 中活跃 Warp 数与最大支持 Warp 数的比值。

• 影响因素：

  • 每个 Block 的线程数

  • 寄存器使用量

  • 共享内存大小

• 优化目标：通常追求 50%~75% 的占用率（非越高越好）。


**(2) Memory Coalescing（内存合并访问）**
• 规则：Warp 中的线程应访问连续内存地址（如 `threadIdx.x` 对应 `data[threadIdx.x]`）。

• 坏例子（步长访问）：

  ```c
  data[threadIdx.x * 2] = ...;  // 导致内存访问不连续
  ```

**(3) Warp Vote/Shuffle 指令**
• 作用：Warp 内线程可通过特殊指令快速通信：

  • `__any_sync()`：任意线程满足条件则返回 true。

  • `__shfl_xor()`：Warp 内线程交换数据。

• 用途：减少共享内存使用，加速规约（Reduction）操作。


---

**4. 如何优化 Warp 效率？**
**(1) 选择合理的 Block 大小**
• 推荐值：每 Block 128~256 个线程（即 4~8 个 Warp）。

• 检查工具：

  ```bash
  nvcc --ptxas-options=-v kernel.cu  # 查看寄存器/共享内存使用
  ```

**(2) 避免 Warp Divergence**
```c
// 坏代码：Warp 内部分线程走不同分支
if (threadIdx.x < 16) { ... } else { ... }

// 好代码：让整个 Warp 走相同分支
if (blockIdx.x < gridDim.x / 2) { ... } else { ... }
```

**(3) 确保内存合并访问**
```c
// 好例子：连续访问
int idx = blockIdx.x * blockDim.x + threadIdx.x;
data[idx] = ...;

// 坏例子：跨步访问
int idx = threadIdx.x * blockDim.x + blockIdx.x;
data[idx] = ...;  // 导致内存访问分散
```

**(4) 使用快速 Warp 操作**
```c
// 计算 Warp 内所有线程的最大值
float val = ...;
for (int offset = 16; offset > 0; offset /= 2) {
    val = max(val, __shfl_down_sync(0xFFFFFFFF, val, offset));
}
```

---

**5. 实际案例分析**
**案例：向量求和优化**
**原始版本（低效）**
```c
__global__ void sum(float *data) {
    int tid = threadIdx.x;
    for (int stride = 1; stride < blockDim.x; stride *= 2) {
        if (tid % (2 * stride) == 0) {  // 导致 Warp Divergence!
            data[tid] += data[tid + stride];
        }
        __syncthreads();
    }
}
```

**优化版本（高效）**
```c
__global__ void sum(float *data) {
    int tid = threadIdx.x;
    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1) {
        if (tid < stride) {  // 无 Warp Divergence
            data[tid] += data[tid + stride];
        }
        __syncthreads();
    }
}
```

---

**6. 总结**
| 关键点 | 优化建议 |
|--------|----------|
| Warp 大小 | 始终 32 线程，Block 大小应为 32 的倍数 |
| 分支处理 | 避免 Warp 内部分化（尽量让整个 Warp 走相同分支） |
| 内存访问 | 确保 Warp 内线程访问连续内存地址 |
| 指令效率 | 使用 `__shfl_sync()` 等 Warp 级指令减少通信开销 |

理解 Warp 是 CUDA 高性能编程的核心！