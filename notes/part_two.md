## 理解线程束执行的本质(Part I)

CUDA执行所有的线程，并行的，没有先后次序的，但实际上硬件资源是有限的，不可能同时执行百万个线程，所以从硬件角度来看，物理层面上执行的也只是线程的一部分，而每次执行的这一部分，就是我们前面提到的线程束。

### 线程束和线程块

线程束是SM中基本的执行单元，当一个网格被启动（网格被启动，等价于一个内核被启动，每个内核对应于自己的网格），网格中包含线程块，线程块被分配到某一个SM上以后，将分为多个线程束，每个线程束一般是32个线程（目前的GPU都是32个线程，但不保证未来还是32个）在一个线程束中，所有线程按照单指令多线程SIMT的方式执行，每一步执行相同的指令，但是处理的数据为私有的数据

如图：
![如图](https://face2ai.com/CUDA-F-3-2-%E7%90%86%E8%A7%A3%E7%BA%BF%E7%A8%8B%E6%9D%9F%E6%89%A7%E8%A1%8C%E7%9A%84%E6%9C%AC%E8%B4%A8-P1/3_10.png )

线程束和线程块，一个是**硬件层面的线程集合**，一个是**逻辑层面的线程集合**，我们编程时为了程序正确，必须从逻辑层面计算清楚，但是为了得到更快的程序，硬件层面是我们应该注意的。

### 线程束分化

给出一个简单的代码：

```cpp
if (con)
{
    //do something
}
else
{
    //do something
}
```

对于GPU，当一个线程束的32个线程执行这段代码的时候，如果其中16个执行if中的代码段，而另外16个执行else中的代码块，同一个线程束中的线程，执行不同的指令，这叫做**线程束的分化。**

不过考虑这个前提：
线程束中的所有线程执行相同的指令，但是线程束又是分化的，所以这似乎是相悖的

解决矛盾的办法就是每个线程都执行所有的if和else部分，当一部分con成立的时候，执行if块内的代码，有一部分线程con不成立，那么他们怎么办？**不管什么都不做**，再进行下一轮（也就是下一个指令）线程束分化会产生严重的性能下降。条件分支越多，并行性削弱越严重。

因为线程束分化导致的性能下降就应该用线程束的方法解决，根本思路是避免同一个线程束内的线程分化，而让我们能控制线程束内线程行为的原因是线程块中线程分配到线程束是有规律的而不是随机的。这就使得我们根据线程编号来设计分支是可以的，**补充说明下，当一个线程束中所有的线程都执行if或者，都执行else时，不存在性能下降；只有当线程束内有分歧产生分支的时候，性能才会急剧下降。**

```cpp
__global__ void mathKernel2(float *c)
{
	int tid = blockIdx.x* blockDim.x + threadIdx.x;
	float a = 0.0;
	float b = 0.0;
	if ((tid/warpSize) % 2 == 0) //warpSize 是 CUDA 的线程束大小（通常为 32）
	{
		a = 100.0f;
	}
	else
	{
		b = 200.0f;
	}
	c[tid] = a + b;
}

//​​逻辑​​：
//如果 (tid / 32) % 2 == 0（即每 ​​64 个连续线程​​为一组，前 32 个线程执行 a=100，后 32 个执行 b=200）。
```

### 事件和指标
事件是可计算的活动，比如这个分支就是一个可以计算的活动，对应一个在内和执行期间被搜集的硬件计数器。
指标是内核的特征，有一个或多个事件计算得到。

## 理解线程束执行的本质(Part II)

### 资源分配

上面我们谈到没执行的线程束情况，这里可以分为两类：
- 已经激活的，也就是说这类线程束其实已经在SM上准备就绪了，只是没轮到他执行，这时候他的状态叫做阻塞
- 一类可能分配到SM了，但是还没上到片上，这类我称之为未激活线程束

每个SM上有多少个线程束处于激活状态，取决于以下资源：

- 程序计数器
- 寄存器
- 共享内存

关于寄存器资源的分配：
![](https://face2ai.com/CUDA-F-3-2-%E7%90%86%E8%A7%A3%E7%BA%BF%E7%A8%8B%E6%9D%9F%E6%89%A7%E8%A1%8C%E7%9A%84%E6%9C%AC%E8%B4%A8-P2/3_13.png)

关于共享内存的分配：
![](https://face2ai.com/CUDA-F-3-2-%E7%90%86%E8%A7%A3%E7%BA%BF%E7%A8%8B%E6%9D%9F%E6%89%A7%E8%A1%8C%E7%9A%84%E6%9C%AC%E8%B4%A8-P2/3_14.png)

当寄存器和共享内存分配给了线程块，这个线程块处于活跃状态，所包含的线程束称为活跃线程束。
活跃的线程束又分为三类：

- 选定的线程束
- 阻塞的线程束
- 符合条件的线程束

当SM要执行某个线程束的时候，执行的这个线程束叫做选定的线程束，准备要执行的叫符合条件的线程束，如果线程束不符合条件还没准备好就是阻塞的线程束。

## 避免分支分化

### 并行规约问题

归约问题最常见的加法计算是把向量的数据分成对，然后用不同线程计算每一对元素，得到的结果作为输入继续分成对，迭代的进行，直到最后一个元素。
成对的划分常见的方法有以下两种：

1、相邻配对：元素与他们相邻的元素配对：
![](https://face2ai.com/CUDA-F-3-4-%E9%81%BF%E5%85%8D%E5%88%86%E6%94%AF%E5%88%86%E5%8C%96/xianglin.png)

2、交错配对：元素与一定距离的元素配对：
![](https://face2ai.com/CUDA-F-3-4-%E9%81%BF%E5%85%8D%E5%88%86%E6%94%AF%E5%88%86%E5%8C%96/jiaocuo.png)

### 改善并行规约的分化

如图：
![](https://face2ai.com/CUDA-F-3-4-%E9%81%BF%E5%85%8D%E5%88%86%E6%94%AF%E5%88%86%E5%8C%96/3_21.png)
由于这个条件判断：
```cpp
if ((tid % (2 * stride)) == 0)
```

产生了内核的分化。

改进方案：
![](https://face2ai.com/CUDA-F-3-4-%E9%81%BF%E5%85%8D%E5%88%86%E6%94%AF%E5%88%86%E5%8C%96/3_23.png)

将线程量减少，配比后指定相应的线程。

但内存对不是相邻的了，而是隔了一定距离的，我们可以进而修改：

![](https://face2ai.com/CUDA-F-3-4-%E9%81%BF%E5%85%8D%E5%88%86%E6%94%AF%E5%88%86%E5%8C%96/3_24.png)

### 展开循环

内核里尽量别写分支，分支包括啥，包括if当然还有for之类的循环语句。

## 动态并行
动态并行的好处之一就是能让复杂的内核变得有层次，坏处就是写出来的程序更复杂，因为并行行为本来就不好控制,另一个好处是等到执行的时候再配置创建多少个网格，多少个块，这样就可以动态的利用GPU硬件调度器和加载平衡器了，通过动态调整，来适应负载。并且在内核中启动内核可以减少一部分数据传输消耗。

### 嵌套执行

内核中启动内核，和cpu并行中有一个相似的概念，就是父线程和子线程。子线程由父线程启动，但是到了GPU，这类名词相对多了些，比如父网格，父线程块，父线程，对应的子网格，子线程块，子线程。子网格被父线程启动，且必须在对应的父线程，父线程块，父网格结束之前结束。所有的子网格结束后，父线程，父线程块，父网格才会结束。

如图：
![](https://face2ai.com/CUDA-F-3-6-%E5%8A%A8%E6%80%81%E5%B9%B6%E8%A1%8C/3_26.png)

对于动态并行，有以下几个方面：

- 父网格和子网格共享相同的全局和常量内存。
- 父网格子网格有不同的局部内存
- 有了子网格和父网格间的弱一致性作为保证，父网格和子网格可以对全局内存并发存取。
- 有两个时刻父网格和子网格所见内存一致：子网格启动的时候，子网格结束的时候
- 共享内存和局部内存分别对于线程块和线程来说是私有的
- 局部内存对线程私有，对外不可见。

## 全局内存

[链接](expand_concept/全局内存.md)

## 内存模型概述

### CUDA内存模型

GPU上的内存设备有：

- 寄存器
- 共享内存
- 本地内存
- 常量内存
- 纹理内存
- 全局内存

#### 寄存器

寄存器无论是在CPU还是在GPU都是速度最快的内存空间，但是和CPU不同的是GPU的寄存器储量要多一些

#### 本地内存

#### 共享内存

使用`__share__`来修饰核函数。

#### 常量内存

使用`__constant__`来修饰。


